"""
ACE-Step OpenRouter API å‹åŠ›æµ‹è¯•è„šæœ¬

æ”¯æŒå¹¶å‘æµ‹è¯•ï¼Œç”¨äºæµ‹è¯•æœåŠ¡çš„æœ€å¤§ QPS å’Œæ€§èƒ½è¡¨ç°ã€‚

Usage:
    # åŸºæœ¬æµ‹è¯• - 10 å¹¶å‘ï¼Œ100 è¯·æ±‚
    python -m openrouter.stress_test

    # è‡ªå®šä¹‰å‚æ•°æµ‹è¯•
    python -m openrouter.stress_test --concurrency 50 --requests 500

    # é€æ­¥åŠ å‹æµ‹è¯•
    python -m openrouter.stress_test --mode ramp --max-concurrency 100 --step 10

    # æŒç»­å‹æµ‹
    python -m openrouter.stress_test --mode duration --duration 60 --concurrency 20
"""

import argparse
import json
import os
import sys
import time
import threading
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from collections import defaultdict
from datetime import datetime
import queue

import requests


# =============================================================================
# é…ç½®
# =============================================================================

DEFAULT_BASE_URL = "https://api.acemusic.ai"
DEFAULT_CONCURRENCY = 4
DEFAULT_TOTAL_REQUESTS = 100


@dataclass
class RequestResult:
    """å•æ¬¡è¯·æ±‚ç»“æœ"""
    success: bool
    status_code: int
    latency: float  # ç§’
    error_message: str = ""
    timestamp: float = 0.0


@dataclass
class StressTestStats:
    """å‹åŠ›æµ‹è¯•ç»Ÿè®¡æ•°æ®"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    latencies: List[float] = field(default_factory=list)
    errors: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    status_codes: Dict[int, int] = field(default_factory=lambda: defaultdict(int))
    start_time: float = 0.0
    end_time: float = 0.0

    def add_result(self, result: RequestResult):
        """æ·»åŠ è¯·æ±‚ç»“æœ"""
        self.total_requests += 1
        self.status_codes[result.status_code] += 1

        if result.success:
            self.successful_requests += 1
            self.latencies.append(result.latency)
        else:
            self.failed_requests += 1
            self.errors[result.error_message] += 1

    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total_requests == 0:
            return 0.0
        return (self.successful_requests / self.total_requests) * 100

    @property
    def duration(self) -> float:
        """æµ‹è¯•æŒç»­æ—¶é—´"""
        return self.end_time - self.start_time

    @property
    def qps(self) -> float:
        """æ¯ç§’è¯·æ±‚æ•° (QPS)"""
        if self.duration == 0:
            return 0.0
        return self.total_requests / self.duration

    @property
    def successful_qps(self) -> float:
        """æˆåŠŸè¯·æ±‚çš„ QPS"""
        if self.duration == 0:
            return 0.0
        return self.successful_requests / self.duration

    def get_latency_stats(self) -> Dict[str, float]:
        """è·å–å»¶è¿Ÿç»Ÿè®¡æ•°æ®"""
        if not self.latencies:
            return {
                "min": 0.0,
                "max": 0.0,
                "avg": 0.0,
                "median": 0.0,
                "p90": 0.0,
                "p95": 0.0,
                "p99": 0.0,
            }

        sorted_latencies = sorted(self.latencies)
        n = len(sorted_latencies)

        return {
            "min": min(sorted_latencies),
            "max": max(sorted_latencies),
            "avg": statistics.mean(sorted_latencies),
            "median": statistics.median(sorted_latencies),
            "p90": sorted_latencies[int(n * 0.90)] if n > 0 else 0.0,
            "p95": sorted_latencies[int(n * 0.95)] if n > 0 else 0.0,
            "p99": sorted_latencies[int(n * 0.99)] if n > 0 else 0.0,
        }


class StressTester:
    """å‹åŠ›æµ‹è¯•å™¨"""

    def __init__(
        self,
        base_url: str,
        api_key: Optional[str] = None,
        timeout: int = 300,
        test_type: str = "health",
    ):
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.timeout = timeout
        self.test_type = test_type
        self.session = requests.Session()
        self.lock = threading.Lock()
        self.request_counter = 0
        self.live_stats = StressTestStats()

    def get_headers(self) -> dict:
        """æ„å»ºè¯·æ±‚å¤´"""
        headers = {"Content-Type": "application/json"}
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
        return headers

    def make_request(self) -> RequestResult:
        """æ‰§è¡Œå•æ¬¡è¯·æ±‚"""
        start_time = time.time()
        timestamp = start_time

        try:
            if self.test_type == "health":
                resp = requests.get(
                    f"{self.base_url}/health",
                    timeout=self.timeout
                )
            elif self.test_type == "models":
                resp = requests.get(
                    f"{self.base_url}/api/v1/models",
                    headers=self.get_headers(),
                    timeout=self.timeout
                )
            elif self.test_type == "generate":
                payload = self._get_generate_payload()
                resp = requests.post(
                    f"{self.base_url}/v1/chat/completions",
                    headers=self.get_headers(),
                    json=payload,
                    timeout=self.timeout
                )
            elif self.test_type == "instrumental":
                payload = self._get_instrumental_payload()
                resp = requests.post(
                    f"{self.base_url}/v1/chat/completions",
                    headers=self.get_headers(),
                    json=payload,
                    timeout=self.timeout
                )
            else:
                # é»˜è®¤ health
                resp = requests.get(
                    f"{self.base_url}/health",
                    timeout=self.timeout
                )

            latency = time.time() - start_time

            if resp.status_code == 200:
                return RequestResult(
                    success=True,
                    status_code=resp.status_code,
                    latency=latency,
                    timestamp=timestamp
                )
            else:
                return RequestResult(
                    success=False,
                    status_code=resp.status_code,
                    latency=latency,
                    error_message=f"HTTP {resp.status_code}",
                    timestamp=timestamp
                )

        except requests.exceptions.Timeout:
            return RequestResult(
                success=False,
                status_code=0,
                latency=time.time() - start_time,
                error_message="Timeout",
                timestamp=timestamp
            )
        except requests.exceptions.ConnectionError as e:
            return RequestResult(
                success=False,
                status_code=0,
                latency=time.time() - start_time,
                error_message=f"ConnectionError: {str(e)[:50]}",
                timestamp=timestamp
            )
        except Exception as e:
            return RequestResult(
                success=False,
                status_code=0,
                latency=time.time() - start_time,
                error_message=f"{type(e).__name__}: {str(e)[:50]}",
                timestamp=timestamp
            )

    def _get_generate_payload(self) -> dict:
        """è·å–ç”Ÿæˆè¯·æ±‚çš„ payload"""
        return {
            "messages": [
                {"role": "user", "content": "Generate an upbeat pop song about summer"}
            ],
            "sample_mode": True,
            "audio_config": {
                "vocal_language": "en",
                "duration": 30,
            },
        }

    def _get_instrumental_payload(self) -> dict:
        """è·å–çº¯éŸ³ä¹è¯·æ±‚çš„ payload"""
        return {
            "messages": [
                {"role": "user", "content": "<prompt>Epic orchestral cinematic score</prompt>"}
            ],
            "audio_config": {
                "instrumental": True,
                "duration": 30,
            },
        }

    def run_fixed_requests(
        self,
        concurrency: int,
        total_requests: int,
        show_progress: bool = True
    ) -> StressTestStats:
        """å›ºå®šè¯·æ±‚æ•°æ¨¡å¼"""
        stats = StressTestStats()
        stats.start_time = time.time()

        completed = 0
        completed_lock = threading.Lock()

        def worker():
            nonlocal completed
            result = self.make_request()

            with completed_lock:
                completed += 1
                stats.add_result(result)

                if show_progress and completed % 10 == 0:
                    elapsed = time.time() - stats.start_time
                    current_qps = completed / elapsed if elapsed > 0 else 0
                    print(
                        f"\rè¿›åº¦: {completed}/{total_requests} "
                        f"({completed/total_requests*100:.1f}%) | "
                        f"æˆåŠŸ: {stats.successful_requests} | "
                        f"å¤±è´¥: {stats.failed_requests} | "
                        f"å½“å‰ QPS: {current_qps:.2f}",
                        end="", flush=True
                    )

        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = [executor.submit(worker) for _ in range(total_requests)]
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    print(f"\nå·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")

        stats.end_time = time.time()

        if show_progress:
            print()  # æ¢è¡Œ

        return stats

    def run_duration_based(
        self,
        concurrency: int,
        duration: int,
        show_progress: bool = True
    ) -> StressTestStats:
        """æŒç»­æ—¶é—´æ¨¡å¼"""
        stats = StressTestStats()
        stats.start_time = time.time()
        stop_event = threading.Event()

        def worker():
            while not stop_event.is_set():
                result = self.make_request()
                with self.lock:
                    stats.add_result(result)

        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for _ in range(concurrency):
            t = threading.Thread(target=worker, daemon=True)
            t.start()
            threads.append(t)

        # æ˜¾ç¤ºè¿›åº¦
        try:
            end_time = time.time() + duration
            while time.time() < end_time:
                elapsed = time.time() - stats.start_time
                remaining = duration - elapsed
                current_qps = stats.total_requests / elapsed if elapsed > 0 else 0

                if show_progress:
                    print(
                        f"\rå‰©ä½™æ—¶é—´: {remaining:.1f}s | "
                        f"è¯·æ±‚æ•°: {stats.total_requests} | "
                        f"æˆåŠŸ: {stats.successful_requests} | "
                        f"å¤±è´¥: {stats.failed_requests} | "
                        f"QPS: {current_qps:.2f}",
                        end="", flush=True
                    )
                time.sleep(0.5)
        finally:
            stop_event.set()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
        for t in threads:
            t.join(timeout=5)

        stats.end_time = time.time()

        if show_progress:
            print()  # æ¢è¡Œ

        return stats

    def run_ramp_up(
        self,
        max_concurrency: int,
        step: int,
        requests_per_step: int,
        show_progress: bool = True
    ) -> List[Dict[str, Any]]:
        """é€æ­¥åŠ å‹æ¨¡å¼"""
        results = []

        for concurrency in range(step, max_concurrency + 1, step):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•å¹¶å‘æ•°: {concurrency}")
            print("=" * 60)

            stats = self.run_fixed_requests(
                concurrency=concurrency,
                total_requests=requests_per_step,
                show_progress=show_progress
            )

            latency_stats = stats.get_latency_stats()

            result = {
                "concurrency": concurrency,
                "total_requests": stats.total_requests,
                "successful_requests": stats.successful_requests,
                "failed_requests": stats.failed_requests,
                "success_rate": stats.success_rate,
                "qps": stats.qps,
                "successful_qps": stats.successful_qps,
                "avg_latency": latency_stats["avg"],
                "p95_latency": latency_stats["p95"],
                "p99_latency": latency_stats["p99"],
            }
            results.append(result)

            self._print_step_summary(result)

            # çŸ­æš‚ä¼‘æ¯è®©æœåŠ¡æ¢å¤
            time.sleep(2)

        return results


    def _print_step_summary(self, result: Dict[str, Any]):
        """æ‰“å°å•æ­¥æµ‹è¯•æ‘˜è¦"""
        print(f"\nå¹¶å‘æ•° {result['concurrency']} æµ‹è¯•ç»“æœ:")
        print(f"  æ€»è¯·æ±‚æ•°: {result['total_requests']}")
        print(f"  æˆåŠŸ/å¤±è´¥: {result['successful_requests']}/{result['failed_requests']}")
        print(f"  æˆåŠŸç‡: {result['success_rate']:.2f}%")
        print(f"  QPS: {result['qps']:.2f}")
        print(f"  æˆåŠŸ QPS: {result['successful_qps']:.2f}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {result['avg_latency']*1000:.2f}ms")
        print(f"  P95 å»¶è¿Ÿ: {result['p95_latency']*1000:.2f}ms")
        print(f"  P99 å»¶è¿Ÿ: {result['p99_latency']*1000:.2f}ms")


def print_stats(stats: StressTestStats, title: str = "å‹åŠ›æµ‹è¯•ç»“æœ"):
    """æ‰“å°ç»Ÿè®¡ç»“æœ"""
    latency_stats = stats.get_latency_stats()

    print("\n")
    print("=" * 70)
    print(f" {title}")
    print("=" * 70)

    print("\nğŸ“Š åŸºæœ¬ç»Ÿè®¡")
    print("-" * 40)
    print(f"  æ€»è¯·æ±‚æ•°:       {stats.total_requests}")
    print(f"  æˆåŠŸè¯·æ±‚æ•°:     {stats.successful_requests}")
    print(f"  å¤±è´¥è¯·æ±‚æ•°:     {stats.failed_requests}")
    print(f"  æˆåŠŸç‡:         {stats.success_rate:.2f}%")

    print("\nâ±ï¸ æ—¶é—´ç»Ÿè®¡")
    print("-" * 40)
    print(f"  æµ‹è¯•æŒç»­æ—¶é—´:   {stats.duration:.2f} ç§’")
    print(f"  æ€» QPS:         {stats.qps:.2f}")
    print(f"  æˆåŠŸ QPS:       {stats.successful_qps:.2f}")

    print("\nğŸ“ˆ å»¶è¿Ÿç»Ÿè®¡ (æ¯«ç§’)")
    print("-" * 40)
    print(f"  æœ€å°å»¶è¿Ÿ:       {latency_stats['min']*1000:.2f}ms")
    print(f"  æœ€å¤§å»¶è¿Ÿ:       {latency_stats['max']*1000:.2f}ms")
    print(f"  å¹³å‡å»¶è¿Ÿ:       {latency_stats['avg']*1000:.2f}ms")
    print(f"  ä¸­ä½æ•°å»¶è¿Ÿ:     {latency_stats['median']*1000:.2f}ms")
    print(f"  P90 å»¶è¿Ÿ:       {latency_stats['p90']*1000:.2f}ms")
    print(f"  P95 å»¶è¿Ÿ:       {latency_stats['p95']*1000:.2f}ms")
    print(f"  P99 å»¶è¿Ÿ:       {latency_stats['p99']*1000:.2f}ms")

    if stats.status_codes:
        print("\nğŸ“‹ çŠ¶æ€ç åˆ†å¸ƒ")
        print("-" * 40)
        for code, count in sorted(stats.status_codes.items()):
            percentage = (count / stats.total_requests) * 100
            print(f"  {code}:  {count:>8} ({percentage:.1f}%)")

    if stats.errors:
        print("\nâŒ é”™è¯¯åˆ†å¸ƒ (Top 10)")
        print("-" * 40)
        sorted_errors = sorted(stats.errors.items(), key=lambda x: x[1], reverse=True)[:10]
        for error, count in sorted_errors:
            percentage = (count / stats.total_requests) * 100
            print(f"  {error[:50]}: {count} ({percentage:.1f}%)")

    print("\n" + "=" * 70)


def print_ramp_summary(results: List[Dict[str, Any]]):
    """æ‰“å°é€æ­¥åŠ å‹æµ‹è¯•çš„æ±‡æ€»"""
    print("\n")
    print("=" * 90)
    print(" é€æ­¥åŠ å‹æµ‹è¯•æ±‡æ€»")
    print("=" * 90)

    # è¡¨å¤´
    print(f"\n{'å¹¶å‘':>8} | {'è¯·æ±‚æ•°':>8} | {'æˆåŠŸç‡':>8} | {'QPS':>10} | {'æˆåŠŸQPS':>10} | {'å¹³å‡å»¶è¿Ÿ':>10} | {'P99å»¶è¿Ÿ':>10}")
    print("-" * 90)

    # æ•°æ®è¡Œ
    for r in results:
        print(
            f"{r['concurrency']:>8} | "
            f"{r['total_requests']:>8} | "
            f"{r['success_rate']:>7.1f}% | "
            f"{r['qps']:>10.2f} | "
            f"{r['successful_qps']:>10.2f} | "
            f"{r['avg_latency']*1000:>9.1f}ms | "
            f"{r['p99_latency']*1000:>9.1f}ms"
        )

    print("-" * 90)

    # æ‰¾å‡ºæœ€ä½³ QPS
    best_qps = max(results, key=lambda x: x['successful_qps'])
    print(f"\nğŸ† æœ€ä½³æˆåŠŸ QPS: {best_qps['successful_qps']:.2f} (å¹¶å‘æ•°: {best_qps['concurrency']})")

    # æ‰¾å‡ºå»¶è¿Ÿç“¶é¢ˆç‚¹ï¼ˆP99 å»¶è¿Ÿå¼€å§‹æ€¥å‰§ä¸Šå‡çš„ç‚¹ï¼‰
    for i in range(1, len(results)):
        if results[i]['p99_latency'] > results[i-1]['p99_latency'] * 2:
            print(f"âš ï¸  å»¶è¿Ÿç“¶é¢ˆç‚¹: å¹¶å‘æ•° {results[i]['concurrency']} (P99 å»¶è¿Ÿå¼€å§‹æ€¥å‰§ä¸Šå‡)")
            break

    # æ‰¾å‡ºé”™è¯¯ç‡å¼€å§‹ä¸Šå‡çš„ç‚¹
    for i, r in enumerate(results):
        if r['success_rate'] < 99:
            print(f"âš ï¸  ç¨³å®šæ€§ä¸‹é™ç‚¹: å¹¶å‘æ•° {r['concurrency']} (æˆåŠŸç‡: {r['success_rate']:.1f}%)")
            break

    print()


def main():
    parser = argparse.ArgumentParser(
        description="ACE-Step OpenRouter API å‹åŠ›æµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¥åº·æ£€æŸ¥æ¥å£å‹æµ‹
  python -m openrouter.stress_test --test health --concurrency 100 --requests 1000

  # æ¨¡å‹åˆ—è¡¨æ¥å£å‹æµ‹
  python -m openrouter.stress_test --test models --concurrency 50 --requests 500

  # éŸ³ä¹ç”Ÿæˆæ¥å£å‹æµ‹ (æ³¨æ„: ç”Ÿæˆè¯·æ±‚è¾ƒæ…¢)
  python -m openrouter.stress_test --test generate --concurrency 5 --requests 20

  # é€æ­¥åŠ å‹æµ‹è¯•
  python -m openrouter.stress_test --mode ramp --max-concurrency 100 --step 10

  # æŒç»­æ—¶é—´å‹æµ‹ (60ç§’)
  python -m openrouter.stress_test --mode duration --duration 60 --concurrency 50
        """
    )

    parser.add_argument(
        "--base-url",
        default=os.getenv("OPENROUTER_BASE_URL", DEFAULT_BASE_URL),
        help=f"API åŸºç¡€ URL (é»˜è®¤: {DEFAULT_BASE_URL})"
    )
    parser.add_argument(
        "--api-key",
        default=os.getenv("OPENROUTER_API_KEY"),
        help="API å¯†é’¥ (å¯é€‰)"
    )
    parser.add_argument(
        "--test",
        choices=["health", "models", "generate", "instrumental"],
        default="health",
        help="è¦æµ‹è¯•çš„æ¥å£ç±»å‹ (é»˜è®¤: health)"
    )
    parser.add_argument(
        "--mode",
        choices=["fixed", "duration", "ramp"],
        default="fixed",
        help="æµ‹è¯•æ¨¡å¼: fixed=å›ºå®šè¯·æ±‚æ•°, duration=æŒç»­æ—¶é—´, ramp=é€æ­¥åŠ å‹ (é»˜è®¤: fixed)"
    )
    parser.add_argument(
        "--concurrency", "-c",
        type=int,
        default=DEFAULT_CONCURRENCY,
        help=f"å¹¶å‘æ•° (é»˜è®¤: {DEFAULT_CONCURRENCY})"
    )
    parser.add_argument(
        "--requests", "-n",
        type=int,
        default=DEFAULT_TOTAL_REQUESTS,
        help=f"æ€»è¯·æ±‚æ•° (fixed æ¨¡å¼) (é»˜è®¤: {DEFAULT_TOTAL_REQUESTS})"
    )
    parser.add_argument(
        "--duration", "-d",
        type=int,
        default=60,
        help="æµ‹è¯•æŒç»­æ—¶é—´ç§’æ•° (duration æ¨¡å¼) (é»˜è®¤: 60)"
    )
    parser.add_argument(
        "--max-concurrency",
        type=int,
        default=100,
        help="æœ€å¤§å¹¶å‘æ•° (ramp æ¨¡å¼) (é»˜è®¤: 100)"
    )
    parser.add_argument(
        "--step",
        type=int,
        default=10,
        help="å¹¶å‘å¢é•¿æ­¥é•¿ (ramp æ¨¡å¼) (é»˜è®¤: 10)"
    )
    parser.add_argument(
        "--requests-per-step",
        type=int,
        default=100,
        help="æ¯ä¸ªæ­¥éª¤çš„è¯·æ±‚æ•° (ramp æ¨¡å¼) (é»˜è®¤: 100)"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=300,
        help="è¯·æ±‚è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: 300)"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        help="è¾“å‡ºç»“æœåˆ° JSON æ–‡ä»¶"
    )
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="å‡å°‘è¾“å‡ºä¿¡æ¯"
    )

    args = parser.parse_args()

    # æ‰“å°é…ç½®ä¿¡æ¯
    print("=" * 70)
    print(" ACE-Step OpenRouter API å‹åŠ›æµ‹è¯•")
    print("=" * 70)
    print(f"  æ—¶é—´:           {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  Base URL:       {args.base_url}")
    print(f"  API Key:        {'å·²è®¾ç½®' if args.api_key else 'æœªè®¾ç½®'}")
    print(f"  æµ‹è¯•æ¥å£:       {args.test}")
    print(f"  æµ‹è¯•æ¨¡å¼:       {args.mode}")

    if args.mode == "fixed":
        print(f"  å¹¶å‘æ•°:         {args.concurrency}")
        print(f"  æ€»è¯·æ±‚æ•°:       {args.requests}")
    elif args.mode == "duration":
        print(f"  å¹¶å‘æ•°:         {args.concurrency}")
        print(f"  æŒç»­æ—¶é—´:       {args.duration} ç§’")
    elif args.mode == "ramp":
        print(f"  æœ€å¤§å¹¶å‘æ•°:     {args.max_concurrency}")
        print(f"  æ­¥é•¿:           {args.step}")
        print(f"  æ¯æ­¥è¯·æ±‚æ•°:     {args.requests_per_step}")

    print(f"  è¯·æ±‚è¶…æ—¶:       {args.timeout} ç§’")
    print("=" * 70)

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = StressTester(
        base_url=args.base_url,
        api_key=args.api_key,
        timeout=args.timeout,
        test_type=args.test
    )

    # æ‰§è¡Œæµ‹è¯•
    try:
        if args.mode == "fixed":
            print(f"\nå¼€å§‹å›ºå®šè¯·æ±‚æ•°æµ‹è¯• (å¹¶å‘: {args.concurrency}, è¯·æ±‚æ•°: {args.requests})...\n")
            stats = tester.run_fixed_requests(
                concurrency=args.concurrency,
                total_requests=args.requests,
                show_progress=not args.quiet
            )
            print_stats(stats, f"å‹åŠ›æµ‹è¯•ç»“æœ - {args.test.upper()} æ¥å£")

            # ä¿å­˜ç»“æœ
            if args.output:
                latency_stats = stats.get_latency_stats()
                output_data = {
                    "test_type": args.test,
                    "mode": args.mode,
                    "concurrency": args.concurrency,
                    "total_requests": stats.total_requests,
                    "successful_requests": stats.successful_requests,
                    "failed_requests": stats.failed_requests,
                    "success_rate": stats.success_rate,
                    "duration": stats.duration,
                    "qps": stats.qps,
                    "successful_qps": stats.successful_qps,
                    "latency": latency_stats,
                    "status_codes": dict(stats.status_codes),
                    "errors": dict(stats.errors),
                    "timestamp": datetime.now().isoformat()
                }
                with open(args.output, "w") as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                print(f"\nç»“æœå·²ä¿å­˜åˆ°: {args.output}")

        elif args.mode == "duration":
            print(f"\nå¼€å§‹æŒç»­æ—¶é—´æµ‹è¯• (å¹¶å‘: {args.concurrency}, æ—¶é•¿: {args.duration}ç§’)...\n")
            stats = tester.run_duration_based(
                concurrency=args.concurrency,
                duration=args.duration,
                show_progress=not args.quiet
            )
            print_stats(stats, f"å‹åŠ›æµ‹è¯•ç»“æœ - {args.test.upper()} æ¥å£ ({args.duration}ç§’)")

        elif args.mode == "ramp":
            print(f"\nå¼€å§‹é€æ­¥åŠ å‹æµ‹è¯• (æœ€å¤§å¹¶å‘: {args.max_concurrency}, æ­¥é•¿: {args.step})...\n")
            results = tester.run_ramp_up(
                max_concurrency=args.max_concurrency,
                step=args.step,
                requests_per_step=args.requests_per_step,
                show_progress=not args.quiet
            )
            print_ramp_summary(results)

            # ä¿å­˜ç»“æœ
            if args.output:
                output_data = {
                    "test_type": args.test,
                    "mode": args.mode,
                    "max_concurrency": args.max_concurrency,
                    "step": args.step,
                    "requests_per_step": args.requests_per_step,
                    "results": results,
                    "timestamp": datetime.now().isoformat()
                }
                with open(args.output, "w") as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")

    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\næµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
