{
  "app": {
    "title": "ğŸ›ï¸ ACE-Step V1.5 PlaygroundğŸ’¡",
    "subtitle": "Pushing the Boundaries of Open-Source Music Generation"
  },
  "dataset": {
    "title": "ğŸ“Š Dataset Explorer",
    "dataset_label": "Dataset",
    "dataset_info": "Choose dataset to explore",
    "import_btn": "ğŸ“¥ Import Dataset",
    "search_type_label": "Search Type",
    "search_type_info": "How to find items",
    "search_value_label": "Search Value",
    "search_value_placeholder": "Enter keys or index (leave empty for random)",
    "search_value_info": "Keys: exact match, Index: 0 to dataset size-1",
    "instruction_label": "ğŸ“ Instruction",
    "instruction_placeholder": "No instruction available",
    "metadata_title": "ğŸ“‹ Item Metadata (JSON)",
    "metadata_label": "Complete Item Information",
    "source_audio": "Source Audio",
    "target_audio": "Target Audio",
    "reference_audio": "Reference Audio",
    "get_item_btn": "ğŸ” Get Item",
    "use_src_checkbox": "Use Source Audio from Dataset",
    "use_src_info": "Check to use the source audio from dataset",
    "data_status_label": "ğŸ“Š Data Status",
    "data_status_default": "âŒ No dataset imported",
    "autofill_btn": "ğŸ“‹ Auto-fill Generation Form"
  },
  "service": {
    "title": "ğŸ”§ Service Configuration",
    "checkpoint_label": "Checkpoint File",
    "checkpoint_info": "Select a trained model checkpoint file (full path or filename)",
    "refresh_btn": "ğŸ”„ Refresh",
    "model_path_label": "Main Model Path",
    "model_path_info": "Select the model configuration directory (auto-scanned from checkpoints)",
    "device_label": "Device",
    "device_info": "Processing device (auto-detect recommended)",
    "lm_model_path_label": "5Hz LM Model Path",
    "lm_model_path_info": "Select the 5Hz LM model checkpoint (auto-scanned from checkpoints)",
    "backend_label": "5Hz LM Backend",
    "backend_info": "Select backend for 5Hz LM: vllm (faster) or pt (PyTorch, more compatible)",
    "init_llm_label": "Initialize 5Hz LM",
    "init_llm_info": "Check to initialize 5Hz LM during service initialization",
    "flash_attention_label": "Use Flash Attention",
    "flash_attention_info_enabled": "Enable flash attention for faster inference (requires flash_attn package)",
    "flash_attention_info_disabled": "Flash attention not available (flash_attn package not installed)",
    "offload_cpu_label": "Offload to CPU",
    "offload_cpu_info": "Offload models to CPU when not in use to save GPU memory",
    "offload_dit_cpu_label": "Offload DiT to CPU",
    "offload_dit_cpu_info": "Offload DiT to CPU (needs Offload to CPU)",
    "compile_model_label": "Compile Model",
    "compile_model_info": "Use torch.compile to optimize model (required for quantization)",
    "quantization_label": "INT8 Quantization",
    "quantization_info": "Enable INT8 weight-only quantization to reduce VRAM usage (requires Compile Model)",
    "mlx_dit_label": "MLX DiT (Apple Silicon)",
    "mlx_dit_info_enabled": "Use native MLX for DiT diffusion on Apple Silicon (faster than MPS)",
    "mlx_dit_info_disabled": "MLX not available (requires macOS + Apple Silicon + mlx package)",
    "init_btn": "Initialize Service",
    "status_label": "Status",
    "language_label": "UI Language",
    "language_info": "Select interface language"
  },
  "generation": {
    "required_inputs": "ğŸ“ Required Inputs",
    "task_type_label": "Task Type",
    "task_type_info": "Select the task type for generation",
    "instruction_label": "Instruction",
    "instruction_info": "Instruction is automatically generated based on task type",
    "load_btn": "Load",
    "track_name_label": "Track Name",
    "track_name_info": "Select track name for lego/extract tasks",
    "track_classes_label": "Track Names",
    "track_classes_info": "Select multiple track classes for complete task",
    "audio_uploads": "ğŸµ Audio Uploads",
    "reference_audio": "Reference Audio (optional)",
    "source_audio": "Source Audio (optional)",
    "convert_codes_btn": "Convert to Codes",
    "lm_codes_hints": "ğŸ¼ LM Codes Hints",
    "lm_codes_label": "LM Codes Hints",
    "lm_codes_placeholder": "<|audio_code_10695|><|audio_code_54246|>...",
    "lm_codes_info": "Paste LM codes hints for text2music generation",
    "lm_codes_sample": "LM Codes Hints (Sample {n})",
    "lm_codes_sample_info": "Codes for sample {n}",
    "transcribe_btn": "Transcribe",
    "repainting_controls": "ğŸ¨ Repainting Controls (seconds)",
    "repainting_start": "Repainting Start",
    "repainting_end": "Repainting End",
    "mode_label": "Generation Mode",
    "mode_info": "Simple: describe music in natural language. Custom: full control over caption and lyrics.",
    "mode_simple": "Simple",
    "mode_custom": "Custom",
    "simple_query_label": "Song Description",
    "simple_query_placeholder": "Describe the music you want to create, e.g., 'a soft Bengali love song for a quiet evening'. Leave empty for a random sample.",
    "simple_query_info": "Enter a natural language description of the music you want to generate",
    "simple_vocal_language_label": "Vocal Language (optional)",
    "simple_vocal_language_info": "Select preferred language(s) for lyrics. Use 'unknown' for any language.",
    "create_sample_btn": "Create Sample",
    "caption_title": "ğŸ“ Music Caption",
    "caption_label": "Music Caption (optional)",
    "caption_placeholder": "A peaceful acoustic guitar melody with soft vocals...",
    "caption_info": "Describe the style, genre, instruments, and mood",
    "lyrics_title": "ğŸ“ Lyrics",
    "lyrics_label": "Lyrics (optional)",
    "lyrics_placeholder": "[Verse 1]\\nUnder the starry night\\nI feel so alive...",
    "lyrics_info": "Song lyrics with structure",
    "instrumental_label": "Instrumental",
    "format_btn": "Format",
    "optional_params": "âš™ï¸ Optional Parameters",
    "vocal_language_label": "Vocal Language (optional)",
    "vocal_language_info": "use `unknown` for inst",
    "bpm_label": "BPM (optional)",
    "bpm_info": "leave empty for N/A",
    "keyscale_label": "KeyScale (optional)",
    "keyscale_placeholder": "Leave empty for N/A",
    "keyscale_info": "A-G, #/â™­, major/minor",
    "timesig_label": "Time Signature (optional)",
    "timesig_info": "2/4, 3/4, 4/4...",
    "duration_label": "Audio Duration (seconds)",
    "duration_info": "Use -1 for random",
    "batch_size_label": "Batch Size",
    "batch_size_info": "Number of audio to generate (max 8)",
    "advanced_settings": "ğŸ”§ Advanced Settings",
    "inference_steps_label": "DiT Inference Steps",
    "inference_steps_info": "Turbo: max 8, Base: max 200",
    "guidance_scale_label": "DiT Guidance Scale (Only support for base model)",
    "guidance_scale_info": "Higher values follow text more closely",
    "seed_label": "Seed",
    "seed_info": "Use comma-separated values for batches",
    "random_seed_label": "Random Seed",
    "random_seed_info": "Enable to auto-generate seeds",
    "audio_format_label": "Audio Format",
    "audio_format_info": "Audio format for saved files",
    "use_adg_label": "Use ADG",
    "use_adg_info": "Enable Angle Domain Guidance",
    "shift_label": "Shift",
    "shift_info": "Timestep shift factor for base models (range 1.0~5.0, default 3.0). Not effective for turbo models.",
    "infer_method_label": "Inference Method",
    "infer_method_info": "Diffusion inference method. ODE (Euler) is faster, SDE (stochastic) may produce different results.",
    "custom_timesteps_label": "Custom Timesteps",
    "custom_timesteps_info": "Optional: comma-separated values from 1.0 to 0.0 (e.g., '0.97,0.76,0.615,0.5,0.395,0.28,0.18,0.085,0'). Overrides inference steps and shift.",
    "cfg_interval_start": "CFG Interval Start",
    "cfg_interval_end": "CFG Interval End",
    "lm_params_title": "ğŸ¤– LM Generation Parameters",
    "lm_temperature_label": "LM Temperature",
    "lm_temperature_info": "5Hz LM temperature (higher = more random)",
    "lm_cfg_scale_label": "LM CFG Scale",
    "lm_cfg_scale_info": "5Hz LM CFG (1.0 = no CFG)",
    "lm_top_k_label": "LM Top-K",
    "lm_top_k_info": "Top-K (0 = disabled)",
    "lm_top_p_label": "LM Top-P",
    "lm_top_p_info": "Top-P (1.0 = disabled)",
    "lm_negative_prompt_label": "LM Negative Prompt",
    "lm_negative_prompt_placeholder": "Enter negative prompt for CFG (default: NO USER INPUT)",
    "lm_negative_prompt_info": "Negative prompt (use when LM CFG Scale > 1.0)",
    "cot_metas_label": "CoT Metas",
    "cot_metas_info": "Use LM to generate CoT metadata (uncheck to skip LM CoT generation)",
    "cot_language_label": "CoT Language",
    "cot_language_info": "Generate language in CoT (chain-of-thought)",
    "constrained_debug_label": "Constrained Decoding Debug",
    "constrained_debug_info": "Enable debug logging for constrained decoding (check to see detailed logs)",
    "auto_score_label": "Auto Score",
    "auto_score_info": "Automatically calculate quality scores for all generated audios",
    "auto_lrc_label": "Auto LRC",
    "auto_lrc_info": "Automatically generate LRC lyrics timestamps for all generated audios",
    "lm_batch_chunk_label": "LM Batch Chunk Size",
    "lm_batch_chunk_info": "Max items per LM batch chunk (default: 8, limited by GPU memory)",
    "codes_strength_label": "LM Codes Strength",
    "codes_strength_info": "Control how many denoising steps use LM-generated codes",
    "similarity_denoise_label": "Similarity / Denoise",
    "similarity_denoise_info": "Controls how closely the output follows the reference audio. Higher values preserve more structure.",
    "cover_strength_label": "Audio Cover Strength",
    "cover_strength_info": "Control how many denoising steps use cover mode",
    "score_sensitivity_label": "Quality Score Sensitivity",
    "score_sensitivity_info": "Lower = more sensitive (default: 1.0). Adjusts how PMI maps to [0,1]",
    "think_label": "Think",
    "parallel_thinking_label": "ParallelThinking",
    "generate_btn": "ğŸµ Generate Music",
    "autogen_label": "AutoGen",
    "caption_rewrite_label": "CaptionRewrite"
  },
  "results": {
    "title": "ğŸµ Results",
    "generated_music": "ğŸµ Generated Music (Sample {n})",
    "send_to_src_btn": "ğŸ”— Send To Src Audio",
    "save_btn": "ğŸ’¾ Save",
    "score_btn": "ğŸ“Š Score",
    "lrc_btn": "ğŸµ LRC",
    "quality_score_label": "Quality Score (Sample {n})",
    "quality_score_placeholder": "Click 'Score' to calculate perplexity-based quality score",
    "codes_label": "LM Codes (Sample {n})",
    "lrc_label": "Lyrics Timestamps (Sample {n})",
    "lrc_placeholder": "Click 'LRC' to generate timestamps",
    "details_accordion": "ğŸ“Š Score & LRC & LM Codes",
    "generation_status": "Generation Status",
    "current_batch": "Current Batch",
    "batch_indicator": "Batch {current} / {total}",
    "next_batch_status": "Next Batch Status",
    "prev_btn": "â—€ Previous",
    "next_btn": "Next â–¶",
    "restore_params_btn": "â†™ï¸ Apply These Settings to UI (Restore Batch Parameters)",
    "batch_results_title": "ğŸ‘‡ Click here to view batch results & generation details",
    "all_files_label": "ğŸ“ All Generated Files (Download)",
    "generation_details": "Generation Details"
  },
  "messages": {
    "no_audio_to_save": "âŒ No audio to save",
    "save_success": "âœ… Saved audio and metadata to {filename}",
    "save_failed": "âŒ Failed to save: {error}",
    "no_file_selected": "âš ï¸ No file selected",
    "params_loaded": "âœ… Parameters loaded from {filename}",
    "invalid_json": "âŒ Invalid JSON file: {error}",
    "load_error": "âŒ Error loading file: {error}",
    "example_loaded": "ğŸ“ Loaded example from {filename}",
    "example_failed": "Failed to parse JSON file {filename}: {error}",
    "example_error": "Error loading example: {error}",
    "lm_generated": "ğŸ¤– Generated example using LM",
    "lm_fallback": "Failed to generate example using LM, falling back to examples directory",
    "lm_not_initialized": "âŒ 5Hz LM not initialized. Please initialize it first.",
    "autogen_enabled": "ğŸ”„ AutoGen enabled - next batch will generate after this",
    "batch_ready": "âœ… Batch {n} ready! Click 'Next' to view.",
    "batch_generating": "ğŸ”„ Starting background generation for Batch {n}...",
    "batch_failed": "âŒ Background generation failed: {error}",
    "viewing_batch": "âœ… Viewing Batch {n}",
    "at_first_batch": "Already at first batch",
    "at_last_batch": "No next batch available",
    "batch_not_found": "Batch {n} not found in queue",
    "no_batch_data": "No batch data found to restore.",
    "params_restored": "âœ… UI Parameters restored from Batch {n}",
    "scoring_failed": "âŒ Error: Batch data not found",
    "no_codes": "âŒ No audio codes available. Please generate music first.",
    "score_failed": "âŒ Scoring failed: {error}",
    "score_error": "âŒ Error calculating score: {error}",
    "lrc_no_batch_data": "âŒ No batch data found. Please generate music first.",
    "lrc_no_extra_outputs": "âŒ No extra outputs found. Condition tensors not available.",
    "lrc_missing_tensors": "âŒ Missing required tensors for LRC generation.",
    "lrc_sample_not_exist": "âŒ Sample does not exist in current batch.",
    "lrc_empty_result": "âš ï¸ LRC generation produced empty result.",
    "empty_query": "âš ï¸ Please enter a music description.",
    "sample_creation_failed": "âŒ Failed to create sample. Please try again.",
    "sample_created": "âœ… Sample created! Review the caption and lyrics, then click Generate Music.",
    "simple_examples_not_found": "âš ï¸ Simple mode examples directory not found.",
    "simple_examples_empty": "âš ï¸ No example files found in simple mode examples.",
    "simple_example_loaded": "ğŸ² Loaded random example from {filename}",
    "format_success": "âœ… Caption and lyrics formatted successfully",
    "format_failed": "âŒ Format failed: {error}",
    "skipping_metas_cot": "âš¡ Skipping Phase 1 metas COT (sample already formatted)",
    "invalid_timesteps_format": "âš ï¸ Invalid timesteps format. Using default schedule.",
    "timesteps_out_of_range": "âš ï¸ Timesteps must be in range [0, 1]. Using default schedule.",
    "timesteps_count_mismatch": "âš ï¸ Timesteps count ({actual}) differs from inference_steps ({expected}). Using timesteps count."
  },
  "training": {
    "tab_title": "ğŸ“ LoRA Training",
    "tab_dataset_builder": "ğŸ“ Dataset Builder",
    "tab_train_lora": "ğŸš€ Train LoRA",
    "quick_start_title": "ğŸš€ Quick Start",
    "load_dataset_label": "Dataset JSON Path",
    "load_dataset_info": "Load a previously saved dataset",
    "load_btn": "ğŸ“‚ Load",
    "load_status": "Load Status",
    "scan_label": "Audio Directory Path",
    "scan_info": "Scan for audio files (wav, mp3, flac, ogg, opus)",
    "scan_btn": "ğŸ” Scan",
    "scan_status": "Scan Status",
    "found_audio_files": "Found Audio Files",
    "dataset_name": "Dataset Name",
    "dataset_name_placeholder": "Enter dataset name",
    "dataset_settings_header": "Dataset Settings",
    "tag_prepend": "Prepend (tag, caption)",
    "tag_append": "Append (caption, tag)",
    "tag_replace": "Replace caption",
    "step2_title": "Step 2: Auto-Label with AI",
    "step2_instruction": "Click the button below to automatically generate metadata for all audio files using AI:\n- **Caption**: Music style, genre, mood description\n- **BPM**: Beats per minute\n- **Key**: Musical key (e.g., C Major, Am)\n- **Time Signature**: 4/4, 3/4, etc.",
    "step3_title": "Step 3: Preview & Edit",
    "step4_title": "Step 4: Save Dataset",
    "step5_title": "Step 5: Preprocess to Tensors",
    "step5_intro": "**Preprocessing converts your dataset to pre-computed tensors for fast training.**\n\nYou can either:\n- Use the dataset from Steps 1-4 above, **OR**\n- Load an existing dataset JSON file (if you've already saved one)",
    "step5_details": "This step:\n- Encodes audio to VAE latents\n- Encodes captions and lyrics to text embeddings\n- Runs the condition encoder\n- Saves all tensors to `.pt` files\n\nâš ï¸ **This requires the model to be loaded and may take a few minutes.**",
    "train_tensor_selection_desc": "Select the directory containing preprocessed tensor files (`.pt` files).\nThese are created in the \"Dataset Builder\" tab using the \"Preprocess\" button.",
    "all_instrumental": "All Instrumental",
    "all_instrumental_info": "Check if all tracks are instrumental (no vocals)",
    "custom_tag": "Custom Activation Tag",
    "custom_tag_info": "Unique tag to activate this LoRA's style",
    "tag_position": "Tag Position",
    "tag_position_info": "Where to place the custom tag in the caption",
    "genre_ratio": "Genre Ratio (%)",
    "genre_ratio_info": "0%=all Caption, 100%=all Genre. Per-sample override takes priority.",
    "skip_metas": "Skip BPM/Key/Time Signature",
    "skip_metas_info": "Skip BPM/Key/Time Signature generation. Caption and Genre are still generated by LLM.",
    "only_unlabeled": "Only Unlabeled",
    "only_unlabeled_info": "Only label samples without caption (useful for resuming failed labeling)",
    "auto_label_btn": "ğŸ·ï¸ Auto-Label All",
    "label_progress": "Labeling Progress",
    "select_sample": "Select Sample #",
    "select_sample_info": "Choose a sample to preview and edit",
    "audio_preview": "Audio Preview",
    "filename": "Filename",
    "caption": "Caption",
    "genre": "Genre",
    "prompt_override_label": "Prompt Override (this sample)",
    "prompt_override_info": "Override global ratio for this sample",
    "lyrics_editable_label": "Lyrics (editable, used for training)",
    "raw_lyrics_label": "Raw Lyrics (from .txt file)",
    "no_lyrics_placeholder": "(no .txt lyrics file)",
    "bpm": "BPM",
    "key_label": "Key",
    "key_placeholder": "C Major",
    "time_sig": "Time Signature",
    "duration_s": "Duration (s)",
    "language": "Language",
    "instrumental": "Instrumental",
    "save_changes_btn": "ğŸ’¾ Save Changes",
    "edit_status": "Edit Status",
    "save_path": "Save Path",
    "save_path_info": "Path where the dataset JSON will be saved",
    "save_dataset_btn": "ğŸ’¾ Save Dataset",
    "save_status": "Save Status",
    "load_existing_label": "Load Existing Dataset (Optional)",
    "load_existing_info": "Path to a previously saved dataset JSON file",
    "load_dataset_btn": "ğŸ“‚ Load Dataset",
    "tensor_output_dir": "Tensor Output Directory",
    "tensor_output_info": "Directory to save preprocessed tensor files",
    "preprocess_btn": "âš¡ Preprocess",
    "preprocess_progress": "Preprocessing Progress",
    "preprocessed_tensors_dir": "Preprocessed Tensors Directory",
    "preprocessed_tensors_info": "Directory containing preprocessed .pt tensor files",
    "train_section_tensors": "Preprocessed Dataset Selection",
    "train_section_lora": "LoRA Settings",
    "train_section_params": "Training Parameters",
    "dataset_info": "Dataset Info",
    "lora_rank": "LoRA Rank (r)",
    "lora_rank_info": "Higher = more capacity, more memory",
    "lora_alpha": "LoRA Alpha",
    "lora_alpha_info": "Scaling factor (typically 2x rank)",
    "lora_dropout": "LoRA Dropout",
    "learning_rate": "Learning Rate",
    "learning_rate_info": "Start with 3e-4, adjust if needed",
    "max_epochs": "Max Epochs",
    "batch_size": "Batch Size",
    "batch_size_info": "Increase if you have enough VRAM",
    "gradient_accumulation": "Gradient Accumulation",
    "gradient_accumulation_info": "Effective batch = batch_size Ã— accumulation",
    "save_every_n_epochs": "Save Every N Epochs",
    "shift": "Shift",
    "shift_info": "Timestep shift for turbo model",
    "seed": "Seed",
    "output_dir": "Output Directory",
    "output_dir_info": "Directory to save trained LoRA weights",
    "start_training_btn": "ğŸš€ Start Training",
    "stop_training_btn": "â¹ï¸ Stop Training",
    "training_progress": "Training Progress",
    "training_log": "Training Log",
    "training_loss_title": "Training Loss",
    "step": "Step",
    "loss": "Loss",
    "export_header": "Export LoRA",
    "export_path": "Export Path",
    "export_lora_btn": "ğŸ“¦ Export LoRA",
    "export_status": "Export Status"
  }
}
